# cython: language_level=3

from __future__ import print_function, division, absolute_import

from collections import defaultdict, OrderedDict
import logging
import operator
import os

import cython

from sortedcontainers import SortedSet, SortedDict

from .compatibility import unicode
from .config import config
from .metrics import time
from .utils import (All, ignoring, get_ip, get_fileno_limit, log_errors,
                    key_split, validate_key, no_default, DequeHandler)


logger = logging.getLogger('distributed.scheduler')

# XXX duplicate defs in distributed.scheduler
DEFAULT_DATA_SIZE = config.get('default-data-size', 1000)
BANDWIDTH = config.get('bandwidth', 100e6)

LOG_PDB = config.get('pdb-on-err') or os.environ.get('DASK_ERROR_PDB', False)


@cython.cclass
class ClientState(object):
    """
    A simple object holding information about a client.

    .. attribute:: client_key: str

       A unique identifier for this client.  This is generally an opaque
       string generated by the client itself.

    .. attribute:: wants_what: {TaskState}

       A set of tasks this client wants kept in memory, so that it can
       download its result when desired.  This is the reverse mapping of
       :class:`TaskState.who_wants`.

       Tasks are typically removed from this set when the corresponding
       object in the client's space (for example a ``Future`` or a Dask
       collection) gets garbage-collected.

    """
    __slots__ = (
        'client_key',
        'wants_what',
    )
    if cython.compiled:
        client_key = cython.declare(str, visibility='public')
        wants_what = cython.declare(set, visibility='public')

    def __init__(self, client_key):
        self.client_key = client_key
        self.wants_what = set()

    def __repr__(self):
        return "<Client %r>" % (self.client_key,)

    def __str__(self):
        return self.client_key


@cython.cclass
class WorkerState(object):
    """
    A simple object holding information about a worker.

    .. attribute:: worker_key

       This worker's unique key.  This can be its connected address
       (such as ``'tcp://127.0.0.1:8891'``) or an alias (such as ``'alice'``).

    .. attribute:: processing: {TaskState: cost}

       A dictionary of tasks that have been submitted to this worker.
       Each task state is asssociated with the expected cost in seconds
       of running that task, summing both the task's expected computation
       time and the expected communication time of its result.

       Multiple tasks may be submitted to a worker in advance and the worker
       will run them eventually, depending on its execution resources
       (but see :doc:`work-stealing`).

       All the tasks here are in the "processing" state.

       This attribute is kept in sync with :attr:`TaskState.processing_on`.

    .. attribute:: has_what: {TaskState}

       The set of tasks which currently reside on this worker.
       All the tasks here are in the "memory" state.

       This is the reverse mapping of :class:`TaskState.who_has`.

    .. attribute:: nbytes: int

       The total memory size, in bytes, used by the tasks this worker
       holds in memory (i.e. the tasks in this worker's :attr:`has_what`).

    .. attribute:: ncores: int

       The number of CPU cores made available on this worker.

    .. attribute:: resources: {str: Number}

       The available resources on this worker like ``{'gpu': 2}``.
       These are abstract quantities that constrain certain tasks from
       running at the same time on this worker.

    .. attribute:: used_resources: {str: Number}

       The sum of each resource used by all tasks allocated to this worker.
       The numbers in this dictionary can only be less or equal than
       those in this worker's :attr:`resources`.

    .. attribute:: occupancy: Number

       The total expected runtime, in seconds, of all tasks currently
       processing on this worker.  This is the sum of all the costs in
       this worker's :attr:`processing` dictionary.

    """
    # XXX need a state field to signal active/removed?

    __slots__ = (
        'worker_key',
        'ncores',
        'resources',
        'used_resources',
        'nbytes',
        'has_what',
        'processing',
        'occupancy',
        )
    if cython.compiled:
        worker_key = cython.declare(str, visibility='public')
        ncores = cython.declare(int, visibility='public')
        resources = cython.declare(dict, visibility='public')
        used_resources = cython.declare(dict, visibility='public')
        nbytes = cython.declare(int, visibility='public')
        has_what = cython.declare(set, visibility='public')
        processing = cython.declare(dict, visibility='public')
        occupancy = cython.declare(cython.double, visibility='public')

    def __init__(self, worker, ncores):
        self.worker_key = worker
        self.ncores = ncores
        self.resources = {}
        self.used_resources = {}
        self.nbytes = 0
        self.has_what = set()
        self.processing = {}
        self.occupancy = 0.0

    def __repr__(self):
        return "<Worker %r>" % (self.worker_key,)

    def __str__(self):
        return self.worker_key


@cython.cclass
class TaskState(object):
    """
    A simple object holding information about a task.

    .. attribute:: key: str

       The key is the unique identifier of a task, generally formed
       from the name of the function, followed by a hash of the function
       and arguments, like ``'inc-ab31c010444977004d656610d2d421ec'``.

    .. attribute:: prefix: str

       The key prefix, used in certain calculations to get an estimate
       of the task's duration based on the duration of other tasks in the
       same "family" (for example ``'inc'``).

    .. attribute:: run_spec: object

       A specification of how to run the task.  The type and meaning of this
       value is opaque to the scheduler, as it is only interpreted by the
       worker to which the task is sent for executing.

       As a special case, this attribute may also be ``None``, in which case
       the task is "pure data" (such as, for example, a piece of data loaded
       in the scheduler using :meth:`Client.scatter`).  A "pure data" task
       cannot be computed again if its value is lost.

    .. attribute:: priority: tuple

       The priority provides each task with a relative ranking which is used
       to break ties when many tasks are being considered for execution.

       This ranking is generally a 2-item tuple.  The first (and dominant)
       item corresponds to when it was submitted.  Generally, earlier tasks
       take precedence.  The second item is determined by the client, and is
       a way to prioritize tasks within a large graph that may be important,
       such as if they are on the critical path, or good to run in order to
       release many dependencies.  This is explained further in
       :doc:`Scheduling Policy <scheduling-policies>`.

    .. attribute:: state: str

       This task's current state.  Valid states include ``released``,
       ``waiting``, ``no-worker``, ``processing``, ``memory``, ``erred``
       and ``forgotten``.  If it is ``forgotten``, the task isn't stored
       in the ``tasks`` dictionary anymore and will probably disappear
       soon from memory.

    .. attribute:: dependencies: {TaskState}

       The set of tasks this task depends on for proper execution.  Only
       tasks still alive are listed in this set.  If, for whatever reason,
       this task also depends on a forgotten task, the
       :attr:`has_lost_dependencies` flag is set.

       A task can only be executed once all its dependencies have already
       been successfully executed and have their result stored on at least
       one worker.  This is tracked by progressively draining the
       :attr:`waiting_on` set.

    .. attribute:: dependents: {TaskState}

       The set of tasks which depend on this task.  Only tasks still alive
       are listed in this set.

       This is the reverse mapping of :attr:`dependencies`.

    .. attribute:: has_lost_dependencies: bool

       Whether any of the dependencies of this task has been forgotten.
       For memory consumption reasons, forgotten tasks are not kept in
       memory even though they may have dependent tasks.  When a task is
       forgotten, therefore, each of its dependents has their
       :attr:`has_lost_dependencies` attribute set to ``True``.

       If :attr:`has_lost_dependencies` is true, this task cannot go
       into the "processing" state anymore.

    .. attribute:: waiting_on: {TaskState}

       The set of tasks this task is waiting on *before* it can be executed.
       This is always a subset of :attr:`dependencies`.  Each time one of the
       dependencies has finished processing, it is removed from the
       :attr:`waiting_on` set.

       Once :attr:`waiting_on` becomes empty, this task can move from the
       "waiting" state to the "processing" state (unless one of the
       dependencies errored out, in which case this task is instead
       marked "erred").

    .. attribute:: waiters: {TaskState}

       The set of tasks which need this task to remain alive.  This is always
       a subset of :attr:`dependents`.  Each time one of the dependents
       has finished processing, it is removed from the :attr:`waiters`
       set.

       Once both :attr:`waiters` and :attr:`who_wants` become empty, this
       task can be released (if it has a non-empty :attr:`run_spec`) or
       forgotten (otherwise) by the scheduler, and by any workers
       in :attr:`who_has`.

       .. note:: Counter-intuitively, :attr:`waiting_on` and
          :attr:`waiters` are not reverse mappings of each other.

    .. attribute:: who_wants: {ClientState}

       The set of clients who want this task's result to remain alive.
       This is the reverse mapping of :attr:`ClientState.wants_what`.

       When a client submits a graph to the scheduler it also specifies
       which output tasks it desires, such that their results are not released
       from memory.

       Once a task has finished executing (i.e. moves into the "memory"
       or "erred" state), the clients in :attr:`who_wants` are notified.

       Once both :attr:`waiters` and :attr:`who_wants` become empty, this
       task can be released (if it has a non-empty :attr:`run_spec`) or
       forgotten (otherwise) by the scheduler, and by any workers
       in :attr:`who_has`.

    .. attribute:: who_has: {WorkerState}

       The set of workers who have this task's result in memory.
       It is non-empty iff the task is in the "memory" state.  There can be
       more than one worker in this set if, for example, :meth:`Client.scatter`
       or :meth:`Client.replicate` was used.

       This is the reverse mapping of :attr:`WorkerState.has_what`.

    .. attribute:: processing_on: WorkerState (or None)

       If this task is in the "processing" state, which worker is currently
       processing it.  Otherwise this is ``None``.

       This attribute is kept in sync with :attr:`WorkerState.processing`.

    .. attribute:: retries: int

       The number of times this task can automatically be retried in case
       of failure.  If a task fails executing (the worker returns with
       an error), its :attr:`retries` attribute is checked.  If it is
       equal to 0, the task is marked "erred".  If it is greater than 0,
       the :attr:`retries` attribute is decremented and execution is
       attempted again.

    .. attribute:: nbytes: int (or None)

       The number of bytes, as determined by ``sizeof``, of the result
       of a finished task.  This number is used for diagnostics and to
       help prioritize work.

    .. attribute:: exception: object

       If this task failed executing, the exception object is stored here.
       Otherwise this is ``None``.

    .. attribute:: traceback: object

       If this task failed executing, the traceback object is stored here.
       Otherwise this is ``None``.

    .. attribute:: exception_blame: TaskState (or None)

       If this task or one of its dependencies failed executing, the
       failed task is stored here (possibly itself).  Otherwise this
       is ``None``.

    .. attribute:: suspicious: int

       The number of times this task has been involved in a worker death.

       Some tasks may cause workers to die (such as calling ``os._exit(0)``).
       When a worker dies, all of the tasks on that worker are reassigned
       to others.  This combination of behaviors can cause a bad task to
       catastrophically destroy all workers on the cluster, one after
       another.  Whenever a worker dies, we mark each task currently
       processing on that worker (as recorded by
       :attr:`WorkerState.processing`) as suspicious.

       If a task is involved in three deaths (or some other fixed constant)
       then we mark the task as ``erred``.

    .. attribute:: host_restrictions: {hostnames}

       A set of hostnames where this task can be run (or ``None`` if empty).
       Usually this is empty unless the task has been specifically restricted
       to only run on certain hosts.  A hostname may correspond to one or
       several connected workers.

    .. attribute:: worker_restrictions: {worker addresses}

       A set of complete worker addresses where this can be run (or ``None``
       if empty).  Usually this is empty unless the task has been specifically
       restricted to only run on certain workers.

       Note this is tracking worker addresses, not worker states, since
       the specific workers may not be connected at this time.

    .. attribute:: resource_restrictions: {resource: quantity}

       Resources required by this task, such as ``{'gpu': 1}`` or
       ``{'memory': 1e9}`` (or ``None`` if empty).  These are user-defined
       names and are matched against the contents of each
       :attr:`WorkerState.resources` dictionary.

    .. attribute:: loose_restrictions: bool

       If ``False``, each of :attr:`host_restrictions`,
       :attr:`worker_restrictions` and :attr:`resource_restrictions` is
       a hard constraint: if no worker is available satisfying those
       restrictions, the task cannot go into the "processing" state and
       will instead go into the "no-worker" state.

       If ``True``, the above restrictions are mere preferences: if no worker
       is available satisfying those restrictions, the task can still go
       into the "processing" state and be sent for execution to another
       connected worker.

    """

    __slots__ = (
        # === General description ===
        # Key name
        'key',
        # Key prefix (see key_split())
        'prefix',
        # How to run the task (None if pure data)
        'run_spec',
        # Alive dependents and dependencies
        'dependencies',
        'dependents',
        # Compute priority
        'priority',
        # Restrictions
        'host_restrictions',
        'worker_restrictions',  # not WorkerStates but addresses
        'resource_restrictions',
        'loose_restrictions',
        # === Task state ===
        'state',
        # Whether some dependencies were forgotten
        'has_lost_dependencies',
        # If in 'waiting' state, which tasks need to complete
        # before we can run
        'waiting_on',
        # If in 'waiting' or 'processing' state, which tasks needs us
        # to complete before they can run
        'waiters',
        # In in 'processing' state, which worker we are processing on
        'processing_on',
        # If in 'memory' state, Which workers have us
        'who_has',
        # Which clients want us
        'who_wants',
        'exception',
        'traceback',
        'exception_blame',
        'suspicious',
        'retries',
        'nbytes',
        )
    if cython.compiled:
        key = cython.declare(object, visibility='public')
        prefix = cython.declare(str, visibility='public')
        run_spec = cython.declare(object, visibility='public')

        dependencies = cython.declare(set, visibility='public')
        dependents = cython.declare(set, visibility='public')
        priority = cython.declare(object, visibility='public')
        host_restrictions = cython.declare(object, visibility='public')
        worker_restrictions = cython.declare(object, visibility='public')
        resource_restrictions = cython.declare(object, visibility='public')
        loose_restrictions = cython.declare(cython.bint, visibility='public')

        state = cython.declare(str, visibility='public')
        has_lost_dependencies = cython.declare(cython.bint, visibility='public')
        waiting_on = cython.declare(set, visibility='public')
        waiters = cython.declare(set, visibility='public')
        processing_on = cython.declare(object, visibility='public')
        who_has = cython.declare(set, visibility='public')
        who_wants = cython.declare(set, visibility='public')

        exception = cython.declare(object, visibility='public')
        traceback = cython.declare(object, visibility='public')
        exception_blame = cython.declare(object, visibility='public')

        suspicious = cython.declare(int, visibility='public')
        retries = cython.declare(int, visibility='public')
        nbytes = cython.declare(cython.Py_ssize_t, visibility='public')

    def __init__(self, key, run_spec):
        self.key = key
        self.prefix = key_split(key)
        self.run_spec = run_spec
        self.state = None
        self.exception = self.traceback = self.exception_blame = None
        self.suspicious = self.retries = 0
        self.nbytes = -1
        self.priority = None
        self.who_wants = set()
        self.dependencies = set()
        self.dependents = set()
        self.waiting_on = set()
        self.waiters = set()
        self.who_has = set()
        self.processing_on = None
        self.has_lost_dependencies = False
        self.host_restrictions = None
        self.worker_restrictions = None
        self.resource_restrictions = None
        self.loose_restrictions = False

    @cython.ccall
    @cython.returns(cython.Py_ssize_t)
    def get_nbytes(self):
        nbytes = self.nbytes
        return nbytes if nbytes >= 0 else DEFAULT_DATA_SIZE

    @cython.ccall
    @cython.locals(nbytes=cython.Py_ssize_t)
    def set_nbytes(self, nbytes):
        old_nbytes = self.nbytes
        diff = nbytes - (old_nbytes or 0)
        for ws in self.who_has:
            ws.nbytes += diff
        self.nbytes = nbytes

    def __repr__(self):
        return "<Task %r %s>" % (self.key, self.state)

    def validate(self):
        for cs in self.who_wants:
            assert isinstance(cs, ClientState), (repr(cs), self.who_wants)
        for ws in self.who_has:
            assert isinstance(ws, WorkerState), (repr(ws), self.who_has)
        for ts in self.dependencies:
            assert isinstance(ts, TaskState), (repr(ts), self.dependencies)
        for ts in self.dependents:
            assert isinstance(ts, TaskState), (repr(ts), self.dependents)
        # XXX
        #validate_task_state(self)


# -------------------------------------------------------------------------


@cython.cclass
class BaseSchedulerState(object):
    """
    """
    if cython.compiled:
        tasks = cython.declare(dict, visibility='public')
        unrunnable = cython.declare(set, visibility='public')
        task_duration = cython.declare(dict, visibility='public')

        workers = cython.declare(object, visibility='public')
        idle = cython.declare(object, visibility='public')
        saturated = cython.declare(set, visibility='public')
        total_occupancy = cython.declare(cython.double, visibility='public')

    def __init__(self):
        self.tasks = dict()
        self.unrunnable = set()
        self.task_duration = {prefix: 0.00001 for prefix in fast_tasks}
        self.unknown_durations = defaultdict(set)

        self.clients = dict()

        # SortedDict and SortedSet used for deterministic round-robin
        # in decide_worker()
        self.workers = SortedDict()
        self.idle = SortedSet(key=operator.attrgetter('worker_key'))
        self.saturated = set()
        self.total_ncores = 0
        self.total_occupancy = 0

        self._transitions = {
            ('released', 'waiting'): self.transition_released_waiting,
            ('waiting', 'released'): self.transition_waiting_released,
            ('waiting', 'processing'): self.transition_waiting_processing,
            ('waiting', 'memory'): self.transition_waiting_memory,
            ('processing', 'released'): self.transition_processing_released,
            ('processing', 'memory'): self.transition_processing_memory,
            ('processing', 'erred'): self.transition_processing_erred,
            ('no-worker', 'released'): self.transition_no_worker_released,
            ('no-worker', 'waiting'): self.transition_no_worker_waiting,
            ('released', 'forgotten'): self.transition_released_forgotten,
            ('memory', 'forgotten'): self.transition_memory_forgotten,
            ('erred', 'forgotten'): self.transition_released_forgotten,
            ('memory', 'released'): self.transition_memory_released,
            ('released', 'erred'): self.transition_released_erred
        }

    #####################
    # State Transitions #
    #####################

    @cython.ccall
    @cython.locals(ts=TaskState, ws=WorkerState)
    def _remove_from_processing(self, ts, send_worker_msg=None):
        """
        Remove *ts* from the set of processing tasks.
        """
        ws = ts.processing_on
        ts.processing_on = None
        w = ws.worker_key
        if w in self.workers:  # may have been removed
            duration = ws.processing.pop(ts)
            if not ws.processing:
                self.total_occupancy -= ws.occupancy
                ws.occupancy = 0
            else:
                self.total_occupancy -= duration
                ws.occupancy -= duration
            self.check_idle_saturated(ws)
            self.release_resources(ts, ws)
            if send_worker_msg:
                self.worker_send(w, send_worker_msg)

    @cython.ccall
    @cython.locals(ts=TaskState, ws=WorkerState, dts=TaskState, cs=ClientState)
    def _add_to_memory(self, ts, ws, recommendations, type=None):
        """
        Add *ts* to the set of in-memory tasks.
        """
        if self.validate:
            assert ts not in ws.has_what

        ts.who_has.add(ws)
        ws.has_what.add(ts)
        ws.nbytes += ts.get_nbytes()

        deps = ts.dependents
        if len(deps) > 1:
            deps = sorted(deps, key=operator.attrgetter('priority'),
                          reverse=True)
        for dts in deps:
            s = dts.waiting_on
            if ts in s:
                s.discard(ts)
                if not s:  # new task ready to run
                    recommendations[dts.key] = 'processing'

        for dts in ts.dependencies:
            s = dts.waiters
            s.discard(ts)
            if not s and not dts.who_wants:
                recommendations[dts.key] = 'released'

        if not ts.waiters and not ts.who_wants:
            recommendations[ts.key] = 'released'
        else:
            msg = {'op': 'key-in-memory',
                   'key': ts.key}
            if type is not None:
                msg['type'] = type
            self.report(msg)

        ts.state = 'memory'

        cs = self.clients['fire-and-forget']
        if ts in cs.wants_what:
            self.client_releases_keys(client='fire-and-forget', keys=[ts.key])

    @cython.ccall
    @cython.locals(ts=TaskState, ws=WorkerState, dts=TaskState, cs=ClientState)
    def transition_released_waiting(self, key):
        try:
            ts = self.tasks[key]

            if self.validate:
                assert ts.run_spec
                assert not ts.waiting_on
                assert not ts.who_has
                assert not ts.processing_on
                assert not any([dts.state == 'forgotten' for dts in ts.dependencies])

            if ts.has_lost_dependencies:
                return {key: 'forgotten'}

            ts.state = 'waiting'

            recommendations = OrderedDict()

            for dts in ts.dependencies:
                if dts.exception_blame:
                    ts.exception_blame = dts.exception_blame
                    recommendations[key] = 'erred'
                    return recommendations

            for dts in ts.dependencies:
                dep = dts.key
                if not dts.who_has:
                    ts.waiting_on.add(dts)
                if dts.state == 'released':
                    recommendations[dep] = 'waiting'
                else:
                    dts.waiters.add(ts)

            ts.waiters = {dts for dts in ts.dependents
                          if dts.state == 'waiting'}

            if not ts.waiting_on:
                if self.workers:
                    recommendations[key] = 'processing'
                else:
                    self.unrunnable.add(ts)
                    ts.state = 'no-worker'

            return recommendations
        except Exception as e:
            logger.exception(e)
            if LOG_PDB:
                import pdb
                pdb.set_trace()
            raise

    @cython.ccall
    @cython.locals(ts=TaskState, ws=WorkerState, dts=TaskState, cs=ClientState)
    def transition_no_worker_waiting(self, key):
        try:
            ts = self.tasks[key]

            if self.validate:
                assert ts in self.unrunnable
                assert not ts.waiting_on
                assert not ts.who_has
                assert not ts.processing_on

            self.unrunnable.remove(ts)

            if ts.has_lost_dependencies:
                return {key: 'forgotten'}

            recommendations = OrderedDict()

            for dts in ts.dependencies:
                dep = dts.key
                if not dts.who_has:
                    ts.waiting_on.add(dep)
                if dts.state == 'released':
                    recommendations[dep] = 'waiting'
                else:
                    dts.waiters.add(ts)

            ts.state = 'waiting'

            if not ts.waiting_on:
                if self.workers:
                    recommendations[key] = 'processing'
                else:
                    self.unrunnable.add(ts)
                    ts.state = 'no-worker'

            return recommendations
        except Exception as e:
            logger.exception(e)
            if LOG_PDB:
                import pdb
                pdb.set_trace()
            raise

    @cython.ccall
    @cython.locals(ts=TaskState, ws=WorkerState, dts=TaskState, cs=ClientState)
    def transition_waiting_processing(self, key):
        try:
            ts = self.tasks[key]

            if self.validate:
                assert not ts.waiting_on
                assert not ts.who_has
                assert not ts.exception_blame
                assert not ts.processing_on
                assert not ts.has_lost_dependencies
                assert ts not in self.unrunnable
                assert all([dts.who_has
                            for dts in ts.dependencies])

            ws = self.decide_worker(ts)
            if ws is None:
                return {}
            worker = ws.worker_key

            duration = self.get_task_duration(ts)
            comm = self.get_comm_cost(ts, ws)

            ws.processing[ts] = duration + comm
            ts.processing_on = ws
            ws.occupancy += duration + comm
            self.total_occupancy += duration + comm
            ts.state = 'processing'
            self.consume_resources(ts, ws)
            self.check_idle_saturated(ws)
            self.n_tasks += 1

            # logger.debug("Send job to worker: %s, %s", worker, key)

            self.send_task_to_worker(worker, key)

            return {}
        except Exception as e:
            logger.exception(e)
            if LOG_PDB:
                import pdb
                pdb.set_trace()
            raise

    @cython.ccall
    @cython.locals(ts=TaskState, ws=WorkerState, dts=TaskState, cs=ClientState)
    def transition_waiting_memory(self, key, nbytes=None, worker=None, type=None):
        try:
            ws = self.workers[worker]
            ts = self.tasks[key]

            if self.validate:
                assert not ts.processing_on
                assert ts.waiting_on
                assert ts.state == 'waiting'

            ts.waiting_on.clear()

            if nbytes is not None:
                ts.set_nbytes(nbytes)

            self.check_idle_saturated(ws)

            recommendations = OrderedDict()

            self._add_to_memory(ts, ws, recommendations, type=type)

            if self.validate:
                assert not ts.processing_on
                assert not ts.waiting_on
                assert ts.who_has

            return recommendations
        except Exception as e:
            logger.exception(e)
            if LOG_PDB:
                import pdb
                pdb.set_trace()
            raise

    @cython.ccall
    @cython.locals(ts=TaskState, ws=WorkerState, dts=TaskState, cs=ClientState)
    def transition_processing_memory(self, key, nbytes=None, type=None,
                                     worker=None, startstops=None):
        try:
            ts = self.tasks[key]
            assert worker
            assert isinstance(worker, (str, unicode))

            if self.validate:
                assert ts.processing_on
                ws = ts.processing_on
                assert ts in ws.processing
                assert not ts.waiting_on
                assert not ts.who_has, (ts, ts.who_has)
                assert not ts.exception_blame
                assert ts.state == 'processing'

            ws = self.workers.get(worker)
            if ws is None:
                return {key: 'released'}

            if ws is not ts.processing_on:  # someone else has this task
                logger.warning("Unexpected worker completed task, likely due to"
                               " work stealing.  Expected: %s, Got: %s, Key: %s",
                               ts.processing_on, ws, key)
                return {}

            if startstops:
                L = [(b, c) for a, b, c in startstops if a == 'compute']
                if L:
                    compute_start, compute_stop = L[0]
                else:  # This is very rare
                    compute_start = compute_stop = None
            else:
                compute_start = compute_stop = None

            #############################
            # Update Timing Information #
            #############################
            if compute_start and ws.processing.get(ts, True):
                cython.declare(avg_duration=cython.double,
                               old=cython.double,
                               comm=cython.double,
                               wws=WorkerState,
                               tts=TaskState)

                # Update average task duration for worker
                info = self.worker_info[worker]
                prefix = ts.prefix
                old_duration = self.task_duration.get(prefix, 0)
                new_duration = compute_stop - compute_start
                if not old_duration:
                    avg_duration = new_duration
                else:
                    avg_duration = (0.5 * old_duration
                                    + 0.5 * new_duration)

                self.task_duration[prefix] = avg_duration

                for tts in self.unknown_durations.pop(prefix, ()):
                    if tts.processing_on:
                        wws = tts.processing_on
                        old = wws.processing[tts]
                        comm = self.get_comm_cost(tts, wws)
                        wws.processing[tts] = avg_duration + comm
                        wws.occupancy += avg_duration + comm - old
                        self.total_occupancy += avg_duration + comm - old

                info['last-task'] = compute_stop

            ############################
            # Update State Information #
            ############################
            if nbytes is not None:
                ts.set_nbytes(nbytes)

            recommendations = OrderedDict()

            self._remove_from_processing(ts)

            self._add_to_memory(ts, ws, recommendations, type=type)

            if self.validate:
                assert not ts.processing_on
                assert not ts.waiting_on

            return recommendations
        except Exception as e:
            logger.exception(e)
            if LOG_PDB:
                import pdb
                pdb.set_trace()
            raise

    @cython.ccall
    @cython.locals(ts=TaskState, ws=WorkerState, dts=TaskState, cs=ClientState)
    def transition_memory_released(self, key, safe=False):
        try:
            ts = self.tasks[key]

            if self.validate:
                assert not ts.waiting_on
                assert not ts.processing_on
                if safe:
                    assert not ts.waiters

            recommendations = OrderedDict()

            for dts in ts.waiters:
                if dts.state in ('no-worker', 'processing'):
                    recommendations[dts.key] = 'waiting'
                elif dts.state == 'waiting':
                    dts.waiting_on.add(ts)

            # XXX factor this out?
            for ws in ts.who_has:
                ws.has_what.remove(ts)
                ws.nbytes -= ts.get_nbytes()
                self.worker_send(ws.worker_key, {'op': 'delete-data',
                                                 'keys': [key],
                                                 'report': False})
            ts.who_has.clear()

            ts.state = 'released'

            self.report({'op': 'lost-data', 'key': key})

            if not ts.run_spec:  # pure data
                recommendations[key] = 'forgotten'
            elif ts.has_lost_dependencies:
                recommendations[key] = 'forgotten'
            elif ts.who_wants or ts.waiters:
                recommendations[key] = 'waiting'

            if self.validate:
                assert not ts.waiting_on

            return recommendations
        except Exception as e:
            logger.exception(e)
            if LOG_PDB:
                import pdb
                pdb.set_trace()
            raise

    @cython.ccall
    @cython.locals(ts=TaskState, ws=WorkerState, dts=TaskState, cs=ClientState)
    def transition_released_erred(self, key):
        try:
            ts = self.tasks[key]

            if self.validate:
                with log_errors(pdb=LOG_PDB):
                    assert ts.exception_blame
                    assert not ts.who_has
                    assert not ts.waiting_on
                    assert not ts.waiters

            recommendations = {}

            failing_ts = ts.exception_blame

            for dts in ts.dependents:
                dts.exception_blame = failing_ts
                if not dts.who_has:
                    recommendations[dts.key] = 'erred'

            self.report({'op': 'task-erred',
                         'key': key,
                         'exception': failing_ts.exception,
                         'traceback': failing_ts.traceback})

            ts.state = 'erred'

            # TODO: waiting data?
            return recommendations
        except Exception as e:
            logger.exception(e)
            if LOG_PDB:
                import pdb
                pdb.set_trace()
            raise

    @cython.ccall
    @cython.locals(ts=TaskState, ws=WorkerState, dts=TaskState, cs=ClientState)
    def transition_waiting_released(self, key):
        try:
            ts = self.tasks[key]

            if self.validate:
                assert not ts.who_has
                assert not ts.processing_on

            recommendations = {}

            for dts in ts.dependencies:
                s = dts.waiters
                if ts in s:
                    s.discard(ts)
                    if not s and not dts.who_wants:
                        recommendations[dts.key] = 'released'
            ts.waiting_on.clear()

            ts.state = 'released'

            if ts.has_lost_dependencies:
                recommendations[key] = 'forgotten'
            elif not ts.exception_blame and (ts.who_wants or ts.waiters):
                recommendations[key] = 'waiting'
            else:
                ts.waiters.clear()

            return recommendations
        except Exception as e:
            logger.exception(e)
            if LOG_PDB:
                import pdb
                pdb.set_trace()
            raise

    @cython.ccall
    @cython.locals(ts=TaskState, ws=WorkerState, dts=TaskState, cs=ClientState)
    def transition_processing_released(self, key):
        try:
            ts = self.tasks[key]

            if self.validate:
                assert ts.processing_on
                assert not ts.who_has
                assert not ts.waiting_on
                assert self.tasks[key].state == 'processing'

            self._remove_from_processing(ts, send_worker_msg={'op': 'release-task',
                                                              'key': key})

            ts.state = 'released'

            recommendations = OrderedDict()

            if ts.has_lost_dependencies:
                recommendations[key] = 'forgotten'
            elif ts.waiters or ts.who_wants:
                recommendations[key] = 'waiting'
            else:
                for dts in ts.dependencies:
                    if dts.state != 'released':
                        s = dts.waiters
                        s.discard(ts)
                        if not s and not dts.who_wants:
                            recommendations[dts.key] = 'released'
                ts.waiters.clear()

            if self.validate:
                assert not ts.processing_on

            return recommendations
        except Exception as e:
            logger.exception(e)
            if LOG_PDB:
                import pdb
                pdb.set_trace()
            raise

    # XXX kwargs
    #@cython.ccall
    def transition_processing_erred(self, key, cause=None, exception=None,
                                    traceback=None, **kwargs):
        try:
            ts = self.tasks[key]

            if self.validate:
                assert cause or ts.exception_blame
                assert ts.processing_on
                assert not ts.who_has
                assert not ts.waiting_on

            self._remove_from_processing(ts)

            if exception is not None:
                ts.exception = exception
            if traceback is not None:
                ts.traceback = traceback
            if cause is not None:
                failing_ts = self.tasks[cause]
                ts.exception_blame = failing_ts
            else:
                failing_ts = ts.exception_blame

            recommendations = {}

            for dts in ts.dependents:
                dts.exception_blame = failing_ts
                recommendations[dts.key] = 'erred'

            for dts in ts.dependencies:
                s = dts.waiters
                s.discard(ts)
                if not s and not dts.who_wants:
                    recommendations[dts.key] = 'released'

            ts.waiters.clear()  # do anything with this?

            ts.state = 'erred'

            self.report({'op': 'task-erred',
                         'key': key,
                         'exception': failing_ts.exception,
                         'traceback': failing_ts.traceback})

            cs = self.clients['fire-and-forget']
            if ts in cs.wants_what:
                self.client_releases_keys(client='fire-and-forget', keys=[key])

            if self.validate:
                assert not ts.processing_on

            return recommendations
        except Exception as e:
            logger.exception(e)
            if LOG_PDB:
                import pdb
                pdb.set_trace()
            raise

    @cython.ccall
    @cython.locals(ts=TaskState, ws=WorkerState, dts=TaskState, cs=ClientState)
    def transition_no_worker_released(self, key):
        try:
            ts = self.tasks[key]

            if self.validate:
                assert self.tasks[key].state == 'no-worker'
                assert not ts.who_has
                assert not ts.waiting_on

            self.unrunnable.remove(ts)
            ts.state = 'released'

            for dts in ts.dependencies:
                dts.waiters.discard(ts)

            ts.waiters.clear()

            return {}
        except Exception as e:
            logger.exception(e)
            if LOG_PDB:
                import pdb
                pdb.set_trace()
            raise

    @cython.ccall
    @cython.locals(ts=TaskState, ws=WorkerState, dts=TaskState, cs=ClientState)
    def remove_key(self, key):
        ts = self.tasks.pop(key)
        assert ts.state == 'forgotten'
        self.unrunnable.discard(ts)
        for cs in ts.who_wants:
            cs.wants_what.remove(ts)
        ts.who_wants.clear()
        ts.processing_on = None
        ts.exception_blame = ts.exception = ts.traceback = None

        if key in self.task_metadata:
            del self.task_metadata[key]

    @cython.ccall
    @cython.locals(ts=TaskState, ws=WorkerState, dts=TaskState, cs=ClientState)
    def _propagate_forgotten(self, ts, recommendations):
        ts.state = 'forgotten'
        key = ts.key
        for dts in ts.dependents:
            dts.has_lost_dependencies = True
            dts.dependencies.remove(ts)
            dts.waiting_on.discard(ts)
            if dts.state not in ('memory', 'error'):
                # Cannot compute task anymore
                recommendations[dts.key] = 'forgotten'
        ts.dependents.clear()
        ts.waiters.clear()

        for dts in ts.dependencies:
            dts.dependents.remove(ts)
            s = dts.waiters
            s.discard(ts)
            if not s and not dts.who_wants:
                # Task not needed anymore
                assert dts is not ts
                recommendations[dts.key] = 'forgotten'
        ts.dependencies.clear()
        ts.waiting_on.clear()

        for ws in ts.who_has:
            ws.has_what.remove(ts)
            ws.nbytes -= ts.get_nbytes()
            w = ws.worker_key
            if w in self.workers:  # in case worker has died
                self.worker_send(w, {'op': 'delete-data',
                                     'keys': [key],
                                     'report': False})
        ts.who_has.clear()

    @cython.ccall
    @cython.locals(ts=TaskState, ws=WorkerState, dts=TaskState, cs=ClientState)
    def transition_memory_forgotten(self, key):
        try:
            ts = self.tasks[key]

            if self.validate:
                assert ts.state == 'memory'
                assert not ts.processing_on
                assert not ts.waiting_on
                if not ts.run_spec:
                    # It's ok to forget a pure data task
                    pass
                elif ts.has_lost_dependencies:
                    # It's ok to forget a task with forgotten dependencies
                    pass
                elif not ts.who_wants and not ts.waiters:
                    # It's ok to forget a task that nobody needs
                    pass
                else:
                    assert 0, (ts,)

            recommendations = {}
            self._propagate_forgotten(ts, recommendations)

            self.report_on_key(ts=ts)
            self.remove_key(key)

            return recommendations
        except Exception as e:
            logger.exception(e)
            if LOG_PDB:
                import pdb
                pdb.set_trace()
            raise

    @cython.ccall
    @cython.locals(ts=TaskState, ws=WorkerState, dts=TaskState, cs=ClientState)
    def transition_released_forgotten(self, key):
        try:
            ts = self.tasks[key]

            if self.validate:
                assert ts.state in ('released', 'erred')
                assert not ts.who_has
                assert not ts.processing_on
                assert not ts.waiting_on, (ts, ts.waiting_on)
                if not ts.run_spec:
                    # It's ok to forget a pure data task
                    pass
                elif ts.has_lost_dependencies:
                    # It's ok to forget a task with forgotten dependencies
                    pass
                elif not ts.who_wants and not ts.waiters:
                    # It's ok to forget a task that nobody needs
                    pass
                else:
                    assert 0, (ts,)

            recommendations = {}
            self._propagate_forgotten(ts, recommendations)

            self.report_on_key(ts=ts)
            self.remove_key(key)

            return recommendations
        except Exception as e:
            logger.exception(e)
            if LOG_PDB:
                import pdb
                pdb.set_trace()
            raise

    # XXX **kwargs
    # @cython.ccall
    def transition(self, key, finish, *args, **kwargs):
        """ Transition a key from its current state to the finish state

        Examples
        --------
        >>> self.transition('x', 'waiting')
        {'x': 'processing'}

        Returns
        -------
        Dictionary of recommendations for future transitions

        See Also
        --------
        Scheduler.transitions: transitive version of this function
        """
        try:
            try:
                ts = self.tasks[key]
            except KeyError:
                return {}
            start = ts.state
            if start == finish:
                return {}

            if (start, finish) in self._transitions:
                func = self._transitions[start, finish]
                recommendations = func(key, *args, **kwargs)
            elif 'released' not in (start, finish):
                func = self._transitions['released', finish]
                assert not args and not kwargs
                a = self.transition(key, 'released')
                if key in a:
                    func = self._transitions['released', a[key]]
                b = func(key)
                a = a.copy()
                a.update(b)
                recommendations = a
                start = 'released'
            else:
                raise RuntimeError("Impossible transition from %r to %r"
                                   % (start, finish))

            finish2 = ts.state
            self.transition_log.append((key, start, finish2, recommendations,
                                        time()))
            if self.validate:
                logger.debug("Transitioned %r %s->%s (actual: %s).  Consequence: %s",
                             key, start, finish2, ts.state, dict(recommendations))
            if self.plugins:
                # Temporarily put back forgotten key for plugin to retrieve it
                if ts.state == 'forgotten':
                    self.tasks[ts.key] = ts
                for plugin in self.plugins:
                    try:
                        plugin.transition(key, start, finish2, *args, **kwargs)
                    except Exception:
                        logger.info("Plugin failed with exception", exc_info=True)
                if ts.state == 'forgotten':
                    del self.tasks[ts.key]

            return recommendations
        except Exception as e:
            logger.exception("Error transitioning %r from %r to %r",
                             key, start, finish)
            if LOG_PDB:
                import pdb
                pdb.set_trace()
            raise

    @cython.ccall
    def transitions(self, recommendations):
        """ Process transitions until none are left

        This includes feedback from previous transitions and continues until we
        reach a steady state
        """
        keys = set()
        recommendations = recommendations.copy()
        while recommendations:
            key, finish = recommendations.popitem()
            keys.add(key)
            new = self.transition(key, finish)
            recommendations.update(new)

        if self.validate:
            for key in keys:
                self.validate_key(key)

    @cython.ccall
    @cython.returns(cython.double)
    @cython.locals(ts=TaskState, ws=WorkerState, dts=TaskState, cs=ClientState,
                   total=cython.Py_ssize_t)
    def get_comm_cost(self, ts, ws):
        """
        Get the estimated communication cost (in s.) to compute the task
        on the given worker.
        """
        total = 0
        for dts in ts.dependencies - ws.has_what:
            total += dts.nbytes
        return total / BANDWIDTH

    @cython.ccall
    @cython.returns(cython.double)
    @cython.locals(ts=TaskState, ws=WorkerState, dts=TaskState, cs=ClientState)
    def get_task_duration(self, ts, default=0.5):
        """
        Get the estimated computation cost of the given task
        (not including any communication cost).
        """
        prefix = ts.prefix
        td = self.task_duration.get(prefix)
        if td is None:
            self.unknown_durations[prefix].add(ts)
            return default
        else:
            return td
        #prefix = ts.prefix
        #try:
            #return self.task_duration[prefix]
        #except KeyError:
            #self.unknown_durations[prefix].add(ts)
            #return default


fast_tasks = {'rechunk-split', 'shuffle-split'}
